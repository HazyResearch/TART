{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with TART!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(f'{os.path.dirname(os.getcwd())}/')\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from tart.tart_modules import Tart\n",
    "from tart.registry import DATASET_REGISTRY\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! Running this notebook with a pre-trained TART head !!\n",
<<<<<<< HEAD
    "* Download [pre-trained TART Reasoning module](https://github.com/HazyResearch/TART/releases/download/initial_release/tart_heads.zip)  --- see the cell below\n",
=======
    "* Download [pre-trained TART Reasoning module](https://github.com/HazyResearch/TART/releases/download/reasoning_module/tart_heads.zip)  --- see the cell below\n",
>>>>>>> e2251a9... Initial commit
    "\n",
    "* Set the location of the downloaded module to `path_tart_weights` in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "! wget https://github.com/HazyResearch/TART/releases/download/initial_release/tart_heads.zip\n",
=======
    "! wget https://github.com/HazyResearch/TART/releases/download/reasoning_module/tart_heads.zip\n",
>>>>>>> e2251a9... Initial commit
    "! unzip tart_heads.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CUSTOMIZE AS NEEDED ####\n",
    "path_tart_weights = '/u/scr/nlp/data/ic-fluffy-head-k-2/3e9724ed-5a49-4070-9b7d-4209a30e2392'\n",
    "cache_dir = '/u/scr/nlp/data/neo/hub'\n",
    "path_tart_config = 'tart_conf.yaml' # if you are using the pre-trained module above, don't change this!\n",
    "data_dir_path = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #1: Set-up TART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_EMBED_MODEL = \"EleutherAI/gpt-neo-125m\"\n",
    "EMBED_METHOD = \"loo\"\n",
    "PATH_TO_PRETRAINED_HEAD = f\"{path_tart_weights}/model_24000.pt\"\n",
    "TART_CONFIG = yaml.load(open(path_tart_config, \"r\"), Loader=yaml.FullLoader)\n",
    "TOTAL_TRAIN_SAMPLES = TART_CONFIG['n_positions'] - 2\n",
    "PATH_TO_FINETUNED_EMBED_MODEL = None\n",
    "CACHE_DIR = cache_dir\n",
    "NUM_PCA_COMPONENTS = 16\n",
    "DOMAIN = \"text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Instantiate TartModule\n",
    "tart_module = Tart(\n",
    "    embed_method=EMBED_METHOD,\n",
    "    embed_model_name=BASE_EMBED_MODEL,\n",
    "    path_to_pretrained_head=PATH_TO_PRETRAINED_HEAD,\n",
    "    tart_head_config=TART_CONFIG,\n",
    "    path_to_finetuned_embed_model=PATH_TO_FINETUNED_EMBED_MODEL,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    num_pca_components=NUM_PCA_COMPONENTS,\n",
    "    domain=DOMAIN\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #2: Load in data...\n",
    "* Here we download datasets from HuggingFace datasets. ``DATASET_NAME`` must be a valid binary classification datset in the HuggingFace datasets library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CUSTOMIZE AS NEEDED ####\n",
    "DATASET_NAME = \"sms_spam\" #ag_news, dbpedia_14, yelp_polarity, hate_speech18\n",
    "seed = 69\n",
    "k_range = [32, 64, 96, 128, 256] #[18, 32, 48, 58, 64]\n",
    "max_eval_samples = 1000\n",
    "pos_class = 0\n",
    "neg_class = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from HF datasets, and sample a class balanced \"train\" set of ICL examples. \n",
    "\n",
    "More concretely, indexing into `X_train_1` with $k$ -- `X_train_1[0:k]` -- returns a list of train samples where $k/2$ of the samples have a positive label and $k/2$ have a negative label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASET_REGISTRY[DOMAIN][DATASET_NAME](\n",
    "    total_train_samples=TOTAL_TRAIN_SAMPLES,\n",
    "    k_range=k_range,\n",
    "    seed=seed,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    max_eval_samples=max_eval_samples,\n",
    "    pos_class=pos_class,\n",
    "    neg_class=neg_class,\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, y_test = dataset.get_dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3: Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_at_k =  {}\n",
    "with torch.no_grad():\n",
    "    for k in k_range:\n",
    "        result = tart_module.evaluate(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            k=k,\n",
    "            seed=seed,\n",
    "            text_threshold=1000\n",
    "        )\n",
    "        results_at_k[k] = result\n",
    "        print(f\"Accuracy at {k} samples: {result['accuracy']}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tart",
   "language": "python",
   "name": "tart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
